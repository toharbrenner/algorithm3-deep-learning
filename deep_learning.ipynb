{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initialize environment"
      ],
      "metadata": {
        "id": "72uqwfleT9Aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hY_5IhBIpNV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "FlKpgh_v0CgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm0sDK-6Pc_D"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKEY0pyyPiNJ"
      },
      "outputs": [],
      "source": [
        "!pip install funcy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwrSAfzqGZwh"
      },
      "outputs": [],
      "source": [
        "!pip install pyrealsense2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import skimage; print(skimage.__version__)\""
      ],
      "metadata": {
        "id": "tYpU8PrDeGd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update pip\n",
        "!python -m pip install -U pip\n",
        "# Install scikit-image\n",
        "!python -m pip install -U scikit-image"
      ],
      "metadata": {
        "id": "_lZaOtc-eMw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -U scikit-image[optional]"
      ],
      "metadata": {
        "id": "VtHj0Dm3eRuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the latest source\n",
        "!git checkout main\n",
        "!git pull upstream main\n",
        "# Update the installation\n",
        "!pip install -e . -vv"
      ],
      "metadata": {
        "id": "doiZwIOfeebl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GSXvdHMwdJCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGVA-578PsJu"
      },
      "outputs": [],
      "source": [
        "# some basic setup:\n",
        "# setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import pyrealsense2 as rs # Intel RealSense cross-platform open-source API\n",
        "import matplotlib.pyplot as plt   \n",
        "import itertools as it           \n",
        "import os, json, cv2, math, random, argparse, funcy, torch, torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
        "from skimage.draw import ellipse\n",
        "from skimage.measure import label, regionprops, regionprops_table\n",
        "from skimage.transform import rotate\n",
        "\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg, CfgNode\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, CityscapesInstanceEvaluator\n",
        "\n",
        "print(\"Environment Ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATy67zmDwcMJ"
      },
      "source": [
        "Split coco annotations (json) into train, validation and test sets - **just for the first time !**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGP4DRI9Zqyb"
      },
      "outputs": [],
      "source": [
        "# def save_coco(file, info, licenses, images, annotations, categories):\n",
        "#     with open(file, 'w') as coco:\n",
        "#         json.dump({ 'info': info, 'licenses': licenses, 'images': images, \n",
        "#             'annotations': annotations, 'categories': categories}, coco, indent=2, sort_keys=True)\n",
        "\n",
        "# def filter_annotations(annotations, images):\n",
        "#     image_ids = funcy.lmap(lambda i: int(i['id']), images)\n",
        "#     return funcy.lfilter(lambda a: int(a['image_id']) in image_ids, annotations)\n",
        "\n",
        "# def main():\n",
        "#   annotations = '/content/drive/MyDrive/Colab Notebooks/tesis/data/instances_default.json'\n",
        "#   ratio = 0.8\n",
        "#   train_path = '/content/drive/MyDrive/Colab Notebooks/tesis/data/train_dataset.json'\n",
        "#   val_path = '/content/drive/MyDrive/Colab Notebooks/tesis/data/val_test_dataset.json'\n",
        "#   having_annotations = True\n",
        "#   with open(annotations, 'r', encoding='UTF-8') as annotations_file:\n",
        "#       coco = json.load(annotations_file)\n",
        "#       info = coco['info']\n",
        "#       licenses = coco['licenses']\n",
        "#       images = coco['images']\n",
        "#       annotations = coco['annotations']\n",
        "#       categories = coco['categories']\n",
        "#       number_of_images = len(images)\n",
        "#       images_with_annotations = funcy.lmap(lambda a: int(a['image_id']), annotations)\n",
        "#       if having_annotations:\n",
        "#           images = funcy.lremove(lambda i: i['id'] not in images_with_annotations, images)\n",
        "#       x, y = train_test_split(images, train_size=ratio)\n",
        "#       save_coco(train_path, info, licenses, x, filter_annotations(annotations, x), categories)\n",
        "#       save_coco(val_path, info, licenses, y, filter_annotations(annotations, y), categories)\n",
        "#       print('finished')\n",
        "\n",
        "# main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7gvH7uh4Nh"
      },
      "outputs": [],
      "source": [
        "# def save_coco(file, info, licenses, images, annotations, categories):\n",
        "#     with open(file, 'w') as coco:\n",
        "#         json.dump({ 'info': info, 'licenses': licenses, 'images': images, \n",
        "#             'annotations': annotations, 'categories': categories}, coco, indent=2, sort_keys=True)\n",
        "\n",
        "# def filter_annotations(annotations, images):\n",
        "#     image_ids = funcy.lmap(lambda i: int(i['id']), images)\n",
        "#     return funcy.lfilter(lambda a: int(a['image_id']) in image_ids, annotations)\n",
        "\n",
        "# def main():\n",
        "#   annotations = '/content/drive/MyDrive/Colab Notebooks/tesis/data/val_test_dataset.json'\n",
        "#   ratio = 0.5\n",
        "#   val_path = '/content/drive/MyDrive/Colab Notebooks/tesis/data/val_dataset.json'\n",
        "#   test_path = '/content/drive/MyDrive/Colab Notebooks/tesis/data/test_dataset.json'\n",
        "#   having_annotations = True\n",
        "#   with open(annotations, 'r', encoding='UTF-8') as annotations_file:\n",
        "#       coco = json.load(annotations_file)\n",
        "#       info = coco['info']\n",
        "#       licenses = coco['licenses']\n",
        "#       images = coco['images']\n",
        "#       annotations = coco['annotations']\n",
        "#       categories = coco['categories']\n",
        "#       number_of_images = len(images)\n",
        "#       images_with_annotations = funcy.lmap(lambda a: int(a['image_id']), annotations)\n",
        "#       if having_annotations:\n",
        "#           images = funcy.lremove(lambda i: i['id'] not in images_with_annotations, images)\n",
        "#       x, y = train_test_split(images, train_size=ratio)\n",
        "#       save_coco(val_path, info, licenses, x, filter_annotations(annotations, x), categories)\n",
        "#       save_coco(test_path, info, licenses, y, filter_annotations(annotations, y), categories)\n",
        "#       print('finished')\n",
        "\n",
        "# main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3UKoV1jYnxi"
      },
      "source": [
        "Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5EPKvMRFlW0"
      },
      "outputs": [],
      "source": [
        "DatasetCatalog.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAHH5ZosYjPw"
      },
      "outputs": [],
      "source": [
        "register_coco_instances(\"train_dataset\", {}, \"/content/drive/MyDrive/Colab Notebooks/tesis/data/train_dataset.json\", \"/content/drive/MyDrive/Colab Notebooks/tesis/data/\")\n",
        "register_coco_instances(\"val_dataset\", {}, \"/content/drive/MyDrive/Colab Notebooks/tesis/data/val_dataset.json\", \"/content/drive/MyDrive/Colab Notebooks/tesis/data/\")\n",
        "# register_coco_instances(\"test_dataset\", {}, \"/content/drive/MyDrive/Colab Notebooks/tesis/all_images/test_dataset.json\", \"/content/drive/MyDrive/Colab Notebooks/tesis/all_images/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m_mtV_LoMCy"
      },
      "source": [
        "Basic configuration\n",
        "https://detectron2.readthedocs.io/en/latest/modules/config.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92QZdDjrbG39"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ1GKdV1UQjK"
      },
      "outputs": [],
      "source": [
        "# tha Back Bone is ResNet50\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"train_dataset\",)\n",
        "cfg.DATASETS.TEST = (\"val_dataset\",)\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  \n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = 2\n",
        "cfg.SOLVER.BASE_LR = 0.01  \n",
        "cfg.SOLVER.MAX_ITER = 2080\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2 # the number of training images per step/iteration\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JYrYeSdoj2u"
      },
      "outputs": [],
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGClRcmruqfV"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Ok-OS_0UdJ"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "5WQs_jD8WAkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # AP50 Evaluation results for segm (IoU=0.7)\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)\n",
        "\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.5)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "evaluator = COCOEvaluator(\"val_dataset\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"val_dataset\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
      ],
      "metadata": {
        "id": "NN1OoKZfOgiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}